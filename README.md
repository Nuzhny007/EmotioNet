EmotioNet

Emotions recognition is a technique to extract the emotions on a human face by the help of software which uses advanced image processing. Facial expressions are the mirror of our feelings. While it is easy to understand the emotion for human beings, a challenging problem emerges when we intend to train a machine how to analyze the data and comprehend the emotions of human in real-time applications. With the help of advances in technology, emotion detection software can record the fundamental facial expressions such as happiness, sadness, anger, surprise, neutral etc.
As human beings, we can recognize emotions easily, but this is really challenging for computers. To do this task, they need to collect, process data and give a fast result at a time of a good many human’ facial emotions. Emotion recognition can be applied in various areas such as health-care, drug testing, video games, website customization, education, advertisements etc. In case of emotion recognition, without learning about any person we can get whether they like something or not and this can be used as mentioned before, for recommendation system in different apps. Our program is going to be base for recommendation system since it will show whether a person likes given object/data or not. It plays a crucial role for the vendor in developing the product that fits the desire of clients and for the client in deciding process. By adding more emotions, it can be used in feedback giving technique which takes facial reaction as an input and predicts how a person feels about a product he/she saw.
Our project’s main aim is to recognize automatically human emotions. It classifies person’s temporal emotional state by given some collected input data. Using the machine learning algorithms, we tried to examine the labeled data’s accuracy by CNN algorithm.
As for the hardware, we needed the camera to capture photos and videos. Getting the face, requires changing colored image to grayscale image, detecting facial features and classifying the object as a face. After getting all the necessary data, we started to train our model. We tried to build our model upon two dataset: AffectNet and Cohn-Kanade.

